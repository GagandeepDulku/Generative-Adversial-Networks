{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bxIACdigTxX",
   "metadata": {
    "id": "2bxIACdigTxX"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbeb48b2",
   "metadata": {
    "id": "cbeb48b2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IOKb-vIacAwX",
   "metadata": {
    "id": "IOKb-vIacAwX"
   },
   "source": [
    "### To use this on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "BnRO0EwfDUgv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnRO0EwfDUgv",
    "outputId": "69f3edc5-2310-4ce7-ff29-9fc13e726236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LVyoLiigcNfB",
   "metadata": {
    "id": "LVyoLiigcNfB"
   },
   "source": [
    "### Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mr-CdXI-RtTw",
   "metadata": {
    "id": "mr-CdXI-RtTw"
   },
   "outputs": [],
   "source": [
    "image_dims = (28, 28, 1) # Shape of the image\n",
    "noise_vect_dim = 100     # size of the generator's input noise vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3e6d0c",
   "metadata": {
    "id": "6e3e6d0c"
   },
   "outputs": [],
   "source": [
    "def create_generator_model(noise_vect_dim = noise_vect_dim, img_dim = image_dims):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    This method create and returns the generator model\n",
    "    \n",
    "    @args\n",
    "      noise_vect_dim = size of the noise vector that is the input to the generator,\n",
    "      img_dim        = dimension of the image that generator suppose to generate.\n",
    "\n",
    "    @returns \n",
    "      model  = Sequential model containing the structure of the generator model  \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(noise_vect_dim,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, img_dim[0], img_dim[1], img_dim[2])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_discriminator_model(img_dim = image_dims):\n",
    "    \n",
    "    \"\"\"\n",
    "    This method creates and returns a sequential model which will be used as discriminator for GAN\n",
    "\n",
    "    @args\n",
    "      img_dims = dimension of the image whose authenticity will be validated by the discriminator\n",
    "    @return\n",
    "      model = Discrminator model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=img_dim))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.15))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.15))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w3MPs695ec3s",
   "metadata": {
    "id": "w3MPs695ec3s"
   },
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c308f8",
   "metadata": {
    "id": "f0c308f8"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \n",
    "    \"\"\"\n",
    "    It computes the loss for the discrminator network using output from the real and generator originated fake images\n",
    "    \n",
    "    @args\n",
    "      real_output = Real_output is the output of the discriminator network when real images were used as input, shape (batch_size, 1)\n",
    "      fake_output = Fake_output is the output of the discriminator network when images created by generator network were used as input, shape = (batch_size, 1)\n",
    "    @returns\n",
    "      total_loss = Total loss after summing the loss from fake and real losses for discriminator\n",
    "    \"\"\"\n",
    " \n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)   # Target labels for the real images are only 1s\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)  # Target labesl for the fake images are only 0s\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    \n",
    "    \"\"\"  \n",
    "    It computes the loss for the generator network  by using comparing the output of the discrimintor in terms of how succssfully the wrong inputs were labeled as real image\n",
    "    @args\n",
    "      fake_output = output of discrmininator when using input images were the generator outputs\n",
    "    @returns\n",
    "      Loss of the discriminator for the fake_output\n",
    "    \n",
    "    \"\"\"\n",
    "    # Target labels are ones because generator loss should decrease by increase no of fake images being labeled as real\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JUxJUrPHeyj2",
   "metadata": {
    "id": "JUxJUrPHeyj2"
   },
   "source": [
    "### Training Step Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d286a7",
   "metadata": {
    "id": "89d286a7"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, batch_size, generator, discriminator, generator_optimizer, discriminator_optimizer, noise_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    This method executes single forward pass for the training of both GANs network\n",
    "\n",
    "    @args\n",
    "      images                  =  (batch_size, image_shape) Real images from mnist dataset to be used by discriminator method\n",
    "      batch_size              =  Size of the batch\n",
    "      generator               =  Generator model to be trained\n",
    "      discriminator           =  Discriminator model to be trained\n",
    "      generator_optimizer     =  Optimization function for generator\n",
    "      discriminator_optimizer =  Discriminator function for generator\n",
    "\n",
    "    @returns\n",
    "      gen_loss  = loss of the generator network\n",
    "      disc_loss = loss of the discriminator network\n",
    "    \"\"\"\n",
    "    \n",
    "    noise = tf.random.normal([batch_size, noise_size, 1])                  # Generate the noise vecotors of batch size\n",
    "        \n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:    # This gradient tape is a tensorflow's way of doing loss minization in 3 distinct steps rather than one (i.e .minimize) \n",
    "        generated_images = generator(noise, training = True)               # Generator generates fake images images\n",
    "        \n",
    "        real_output = discriminator(images, training = True)               # Real image predictions     \n",
    "        fake_output = discriminator(generated_images, training = True)     # Fake image_predictions\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)                             # Generator loss\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)           # Discriminator loss \n",
    "        \n",
    "    gen_gradient = gen_tape.gradient(gen_loss, generator.trainable_variables)                      # Computing the gradient for Generation loss\n",
    "    generator_optimizer.apply_gradients(zip(gen_gradient, generator.trainable_variables))          # Weights updation of generator weights\n",
    "\n",
    "\n",
    "    disc_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)               # Discrminator Gradient Calculation using GradientTape\n",
    "    discriminator_optimizer.apply_gradients(zip(disc_gradient, discriminator.trainable_variables)) # Weights updation of discrminator weights\n",
    "    \n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2c978",
   "metadata": {
    "id": "1cb2c978"
   },
   "source": [
    "### Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c4df02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71c4df02",
    "outputId": "d0a0e30e-eb58-49bd-d470-615072c1b859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()               # Load MNIST dataset\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')  # Reshape and change type of the array\n",
    "train_images = (train_images - 127.5) / 127.5                                            # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f44d0",
   "metadata": {
    "id": "be9f44d0"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23b7f90",
   "metadata": {
    "id": "b23b7f90"
   },
   "outputs": [],
   "source": [
    "lr = .0001        \n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "base_location = \"\" # Base location where training data supposed to be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716417e",
   "metadata": {
    "id": "8716417e"
   },
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13ae41f",
   "metadata": {
    "id": "c13ae41f"
   },
   "outputs": [],
   "source": [
    "generator_model = create_generator_model()\n",
    "discrminator_model = create_discriminator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3bec4",
   "metadata": {
    "id": "67f3bec4"
   },
   "source": [
    "### Define Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4888b641",
   "metadata": {
    "id": "4888b641"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(lr)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e78c53",
   "metadata": {
    "id": "99e78c53"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e42d7af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0e42d7af",
    "outputId": "ebb93940-d4ba-410b-aef2-3483d2e46fb2"
   },
   "outputs": [],
   "source": [
    "gen_loss_ep = []                                                                 # List to save generator loss for each epoch\n",
    "disc_loss_ep = []                                                                # List to save discriminator loss for each epoch\n",
    "\n",
    "run_path = create_training_directory(base_location)                                      # Create a folder for this training session at base location\n",
    "for i in range(epochs):\n",
    "    image_batches = np.array_split(train_images, len(train_images)//batch_size)  # Create a list of image batches\n",
    "    gen_loss_list = []                                                           # List to save generator loss for each batch\n",
    "    disc_loss_list = []                                                          # List to save discriminator loss for each batch\n",
    "    \n",
    "    for bi, batch in enumerate(image_batches):                                   # Iterate over image batch sets \n",
    "        gen_loss, disc_loss = train_step(  images = batch,                           \n",
    "                                           batch_size = batch_size,\n",
    "                                           generator = generator_model,\n",
    "                                           discriminator = discrminator_model,\n",
    "                                           generator_optimizer = generator_optimizer,\n",
    "                                           discriminator_optimizer = discriminator_optimizer,\n",
    "                                           noise_size = noise_vect_dim\n",
    "                                        )\n",
    "        gen_loss_list.append(gen_loss.numpy())\n",
    "        disc_loss_list.append(disc_loss.numpy())\n",
    "    \n",
    "    gen_loss_ep.append(np.mean(gen_loss_list))\n",
    "    disc_loss_ep.append(np.mean(disc_loss_list))\n",
    "    \n",
    "    print(\"----------------------------Epoch\", i+1,\"/\",epochs,\"-----------------------------------\")\n",
    "    print(\"Generator Loss\", gen_loss_ep[-1])\n",
    "    print(\"Discrminator Loss\", disc_loss_ep[-1])\n",
    "    \n",
    "    plot_grids(train_images, generator_model,5 ,5)\n",
    "    \n",
    "    if i > 0:   # Plot only makes sense after first epoch \n",
    "        plot_loss(gen_loss_ep, disc_loss_ep)\n",
    "        \n",
    "    # Save both losses as a numpy array   \n",
    "    np.save(run_path + \"/gen_loss.npy\", np.array(gen_loss_ep))\n",
    "    np.save(run_path + \"/disc_loss.npy\", np.array(disc_loss_ep))\n",
    "    \n",
    "    \n",
    "# Save the training session data\n",
    "generator_model.save(os.path.join(run_path, \"generator_model.h5\"))\n",
    "discrminator_model.save(os.path.join(run_path, \"discrminator_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ef242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
